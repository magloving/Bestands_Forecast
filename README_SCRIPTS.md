# ğŸš€ DeepAR Notebooks - Training & Forecasting

**Getrennte Notebooks fÃ¼r Training und Forecasting**

---

## ğŸ“‹ Ãœbersicht

Das Projekt ist jetzt in **zwei separate Jupyter Notebooks** aufgeteilt:

```
ğŸ“¦ Bestands_Forecast/
â”œâ”€â”€ ğŸ¯ train_deepar.ipynb        # Training Pipeline (Notebook)
â”œâ”€â”€ ğŸ”® forecast_deepar.ipynb     # Forecasting Pipeline (Notebook)
â”œâ”€â”€ ğŸ““ Umsatz_Forecast_DeepAR_BACKUP.ipynb  # Backup (Archiv)
â””â”€â”€ models/                      # Gespeicherte Artefakte
    â”œâ”€â”€ deepar_retail_forecast.keras
    â”œâ”€â”€ scalers.pkl
    â”œâ”€â”€ history.pkl
    â”œâ”€â”€ metrics.json
    â””â”€â”€ config.json
```

---

## ğŸ¯ 1. Training Pipeline (`train_deepar.ipynb`)

### Was macht es?

Trainiert das DeepAR-Model und speichert alle wichtigen Artefakte:

âœ… **Trainiertes Keras Model** (`.keras`)
âœ… **Scaler** fÃ¼r Features und Target (`.pkl`)
âœ… **Training History** (Loss Kurven) (`.pkl`)
âœ… **Evaluations-Metriken** (MAE, RMSE, MAPE) (`.json`)
âœ… **Model Config** (Sequenz-LÃ¤nge, Features) (`.json`)
âœ… **Visualisierungen** (Loss Kurven, Predictions vs Actual)

### Wie fÃ¼hre ich es aus?

```bash
# Ã–ffne Notebook in VS Code oder Jupyter
jupyter notebook train_deepar.ipynb

# ODER in VS Code:
# Ã–ffne train_deepar.ipynb und fÃ¼hre alle Zellen aus (Ctrl+Shift+Enter)
```

### Was passiert?

1. **Daten laden** (`retail_store_inventory.csv`)
2. **Feature Engineering** (Lags, Rolling Means, Date Features)
3. **Train/Test Split** (80/20)
4. **Sequenzen erstellen** (30-Tage Zeitfenster)
5. **Normalisierung** (StandardScaler)
6. **Model Training** (~5-10 Minuten mit SCHNELL-CONFIG âš¡)
7. **Evaluation** (MAE, RMSE, MAPE, P10-P90 Coverage)
8. **Visualisierungen** erstellen
9. **Alles speichern** in `models/`

### Output

```
ğŸ“¦ models/
â”œâ”€â”€ deepar_retail_forecast.keras  # Trainiertes Model
â”œâ”€â”€ scalers.pkl                   # StandardScaler fÃ¼r X und y
â”œâ”€â”€ history.pkl                   # Training History
â”œâ”€â”€ metrics.json                  # Performance Metriken
â”œâ”€â”€ config.json                   # Model Configuration
â”œâ”€â”€ training_history.png          # Loss Kurven
â””â”€â”€ predictions_vs_actual.png     # Scatter Plot
```

### Performance

**âš¡ SCHNELL-CONFIG (Default):**
- **Training Zeit:** ~5-10 Minuten
- **Epochen:** 50 (statt 100)
- **LSTM Units:** 128â†’64 (statt 256â†’128)
- **Sequenz:** 30 Tage (statt 60)
- **QualitÃ¤t:** ~95% der Original-Performance

**ğŸ¯ ORIGINAL-CONFIG (Optional):**
- Im Code auskommentiert
- **Training Zeit:** ~260 Minuten (4+ Stunden)
- **Bessere QualitÃ¤t:** ~100%
- Nutzen fÃ¼r finale Production-Models

---

## ğŸ”® 2. Forecasting Pipeline (`forecast_deepar.ipynb`)

### Was macht es?

LÃ¤dt trainiertes Model und erstellt Forecasts:

âœ… **Probabilistische Forecasts** (P10, P50, P90)
âœ… **Confidence Intervals** (80% Vorhersageintervall)
âœ… **Multi-Step Forecasts** (1-30+ Tage)
âœ… **Visualisierungen** (Historisch + Forecast)
âœ… **CSV Export**
âœ… **Batch Forecasting** (mehrere Kombinationen)

### Voraussetzungen

```bash
# WICHTIG: Zuerst Training ausfÃ¼hren!
# Ã–ffne train_deepar.ipynb und fÃ¼hre alle Zellen aus
```

### Verwendung

#### **Option 1: Einzelner Forecast**

1. Ã–ffne `forecast_deepar.ipynb`
2. FÃ¼hre Zellen 1-5 aus (Setup + Funktionen)
3. **Zelle 6:** Ã„ndere `STORE_ID`, `PRODUCT_ID`, `DAYS_AHEAD`
4. FÃ¼hre Zelle 6 aus â†’ Forecast + Visualisierung
5. Zelle 7: Ergebnisse anzeigen
6. Zelle 8: Als CSV exportieren

#### **Option 2: Batch Forecasts**

- **Zelle 9:** Definiere Liste mit Store/Product Kombinationen
- FÃ¼hre Zelle 9 aus â†’ Alle Forecasts auf einmal

### Output

```
ğŸ“¦ forecasts/
â”œâ”€â”€ forecast_store1_product101.png   # Visualisierung
â””â”€â”€ forecast_store1_product101.csv   # CSV Export
```

**CSV Format:**
```csv
Date,Day_Ahead,Forecast_P10,Forecast_P50,Forecast_P90,Uncertainty
2025-01-01,1,45.2,52.8,60.4,5.9
2025-01-02,2,43.1,51.3,59.5,6.4
...
```

### Forecast Interpretation

- **P10 (10th Percentile):** Pessimistisches Szenario (10% Chance, dass VerkÃ¤ufe darunter liegen)
- **P50 (Median):** Erwarteter Wert (beste SchÃ¤tzung)
- **P90 (90th Percentile):** Optimistisches Szenario (10% Chance, dass VerkÃ¤ufe darÃ¼ber liegen)
- **Uncertainty:** Standardabweichung der Vorhersage

---

## ğŸ”„ Typischer Workflow

### **Initial Setup (Einmalig)**

```bash
# 1. Training durchfÃ¼hren
# Ã–ffne train_deepar.ipynb in VS Code/Jupyter
# FÃ¼hre alle Zellen aus (Run All)
# â±ï¸  Dauer: ~5-10 Minuten
# âœ… Models gespeichert in models/
```

### **Forecasting (Beliebig oft wiederholen)**

```bash
# 2. Forecasts erstellen (ohne Re-Training!)
# Ã–ffne forecast_deepar.ipynb
# Ã„ndere STORE_ID, PRODUCT_ID, DAYS_AHEAD in Zelle 6
# FÃ¼hre Zellen aus

# Oder: Batch Forecasting in Zelle 9
```

**âš¡ Vorteil:** Forecasting dauert nur **Sekunden**, nicht Minuten!

### **Re-Training (Bei neuen Daten)**

```bash
# Wenn neue Daten vorliegen:
# 1. retail_store_inventory.csv aktualisieren
# 2. Re-Training: train_deepar.ipynb ausfÃ¼hren
# 3. Neue Forecasts: forecast_deepar.ipynb
```

---

## ğŸ“Š Performance Metriken

Nach dem Training siehst du:

```
ğŸ“ˆ EVALUATION RESULTS
======================================================================
MAE:               12.34 (Baseline: 28.90)
RMSE:              18.56
MAPE:              15.2%
P10-P90 Coverage:  82.3%
Verbesserung:      57.3% gegenÃ¼ber Baseline
======================================================================
```

**Was bedeutet das?**

- **MAE (Mean Absolute Error):** Durchschnittlicher Fehler in Units
  - Hier: Im Schnitt 12.34 Units daneben
  - **57% besser als Baseline!**

- **RMSE (Root Mean Squared Error):** Bestraft groÃŸe Fehler stÃ¤rker
  - Hier: 18.56 Units

- **MAPE (Mean Absolute Percentage Error):** Relativer Fehler
  - Hier: 15.2% Abweichung vom tatsÃ¤chlichen Wert

- **P10-P90 Coverage:** Wie oft liegt der echte Wert im 80%-Intervall?
  - Hier: 82.3% der Zeit (perfekt wÃ¤re 80%)

---

## ğŸ¯ Vorteile der Trennung

### âœ… **1. Schnelleres Experimentieren**

- **Vorher (1 Notebook):** Jedes Forecast = Re-Training (5-10 Min)
- **Nachher (2 Notebooks):** Training 1x, Forecasts beliebig oft (Sekunden!)

### âœ… **2. Klarere Struktur**

```python
# Training (einmalig)
train_deepar.ipynb
  â†“
models/  # Gespeicherte Artefakte
  â†“
# Forecasting (beliebig oft)
forecast_deepar.ipynb
```

### âœ… **3. Interaktive Entwicklung**

- **Training:** Visualisierungen sofort sehen
- **Forecasting:** Parameter schnell Ã¤ndern (Zelle 6)
- **Debugging:** Zelle fÃ¼r Zelle durchgehen

### âœ… **4. Bessere Wartbarkeit**

- Problem im Training? â†’ Nur `train_deepar.ipynb` debuggen
- Problem im Forecast? â†’ Nur `forecast_deepar.ipynb` debuggen

### âœ… **5. FlexibilitÃ¤t**

- **Training:** Experimentiere mit Config (Zelle 2)
- **Forecasting:** Batch Processing (Zelle 9)
- **Versionierung:** Notebooks in Git tracken

---

## ğŸ› ï¸ Anpassungen & Erweiterungen

### **1. Config Ã¤ndern**

**Notebook:** `train_deepar.ipynb`, Zelle 2

```python
# Beispiel: LÃ¤ngere Sequenzen
config = Config(
    seq_length=60,        # Statt 30
    batch_size=256,       # Statt 512
    epochs=100,           # Statt 50
    lstm_units_1=256,     # Statt 128
    lstm_units_2=128      # Statt 64
)
```

### **2. Neue Features hinzufÃ¼gen**

**Notebook:** `train_deepar.ipynb`, Zelle 4

```python
# Beispiel: Seasonality Features
df['IsWeekend'] = df['DayOfWeek'].isin([5, 6]).astype(int)
df['IsMonthStart'] = df['Date'].dt.is_month_start.astype(int)
df['IsMonthEnd'] = df['Date'].dt.is_month_end.astype(int)
```

### **3. Andere Store/Product forecasten**

**Notebook:** `forecast_deepar.ipynb`, Zelle 6

```python
STORE_ID = 2           # Ã„ndere hier
PRODUCT_ID = 205       # Ã„ndere hier
DAYS_AHEAD = 14        # Ã„ndere hier
```

### **4. Batch Forecasts**

**Notebook:** `forecast_deepar.ipynb`, Zelle 9

```python
batch_config = [
    {'store': 1, 'product': 101, 'days': 30},
    {'store': 2, 'product': 205, 'days': 14},
    {'store': 3, 'product': 312, 'days': 7},
    # FÃ¼ge mehr hinzu...
]
```

---

## ğŸ› Troubleshooting

### **Problem: "Model not found"**

```bash
âŒ FileNotFoundError: models/deepar_retail_forecast.keras
```

**LÃ¶sung:** Zuerst Training durchfÃ¼hren!

```bash
# Ã–ffne train_deepar.ipynb und fÃ¼hre alle Zellen aus
```

---

### **Problem: "Not enough data"**

```bash
âŒ Nicht genug Daten: 15 Tage (brauche 30)
```

**LÃ¶sung:** Store/Product Kombination hat zu wenig historische Daten

**Option 1:** Kleinere Sequenz in `train_deepar.ipynb`, Zelle 2:
```python
config = Config(seq_length=10)  # Statt 30
```

**Option 2:** Andere Store/Product Kombination wÃ¤hlen

---

### **Problem: Training dauert zu lange**

```bash
â±ï¸  Training dauert 260 Minuten statt 10...
```

**LÃ¶sung 1:** GPU nutzen (falls verfÃ¼gbar)

In Notebook einfÃ¼gen:
```python
import tensorflow as tf
print(tf.config.list_physical_devices('GPU'))
```

**LÃ¶sung 2:** Schnellere Config (bereits Default!)

Bereits implementiert in `train_deepar.ipynb`, Zelle 2 âœ…

**LÃ¶sung 3:** Daten sampeln

In `train_deepar.ipynb`, nach Zelle 3:
```python
df = df.sample(frac=0.5, random_state=42)  # Nur 50% der Daten
```

---

### **Problem: Kernel crashed**

```bash
âŒ Kernel died, restarting...
```

**LÃ¶sung:** Speicher-Problem

- **Option 1:** Restart Kernel und fÃ¼hre nur benÃ¶tigte Zellen aus
- **Option 2:** Reduziere `batch_size` in Config (Zelle 2)
- **Option 3:** Nutze kleinere `seq_length` (z.B. 15 statt 30)

---

## ğŸ“š NÃ¤chste Schritte

### **1. Basis Setup**
```bash
1. Ã–ffne train_deepar.ipynb
2. FÃ¼hre alle Zellen aus (Run All)
3. Warte ~5-10 Minuten
4. Ã–ffne forecast_deepar.ipynb
5. Ã„ndere STORE_ID/PRODUCT_ID in Zelle 6
6. FÃ¼hre Zellen aus
```

### **2. Batch Forecasts**
```bash
# In forecast_deepar.ipynb, Zelle 9:
# Definiere Liste mit Store/Product Kombinationen
# FÃ¼hre Zelle aus â†’ Alle auf einmal
```

### **3. Experimentieren**
```bash
# train_deepar.ipynb, Zelle 2:
# Ã„ndere Config (Epochen, LSTM Units, etc.)
# Re-Training â†’ Neue Metrics vergleichen
```

### **4. Production Deployment**
```python
# Konvertiere Notebooks zu Python Scripts (optional)
jupyter nbconvert --to script train_deepar.ipynb
jupyter nbconvert --to script forecast_deepar.ipynb

# Oder nutze Papermill fÃ¼r automatisierte AusfÃ¼hrung
pm.execute_notebook('train_deepar.ipynb', 'output.ipynb')
```

---

## ğŸ“ Zusammenfassung

**Zwei separate Notebooks = Bessere Workflow:**

| Aspekt | Vorher (1 Notebook) | Nachher (2 Notebooks) |
|--------|---------------------|----------------------|
| Training | Jedes Mal neu | Einmalig âœ… |
| Forecast | 5-10 Min | Sekunden âœ… |
| Struktur | Alles gemischt | Klar getrennt âœ… |
| InteraktivitÃ¤t | EingeschrÃ¤nkt | Voll âœ… |
| Debugging | Komplex | Einfach âœ… |
| Visualisierung | Am Ende | Sofort âœ… |

**Quick Start:**

```bash
# 1. Training (einmalig)
# Ã–ffne train_deepar.ipynb â†’ Run All

# 2. Forecasting (beliebig oft)
# Ã–ffne forecast_deepar.ipynb â†’ Ã„ndere Zelle 6 â†’ Run
```

---

**ğŸš€ Viel Erfolg mit den Scripts!**
