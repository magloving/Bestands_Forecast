# ğŸ“Š Bestands Forecast - Retail Inventory Forecasting

**Production-ready Time Series Forecasting mit DeepAR & External Features**

---

## ğŸ¯ Projekt-Ãœbersicht

Probabilistisches Forecasting von ProduktbestÃ¤nden fÃ¼r Retail Stores mit:
- **DeepAR Model**: Konfidenzintervalle & UnsicherheitsschÃ¤tzung
- **External Features**: Feiertage, Zinsen, Wirtschaftsindikatoren
- **Hybrid Data Strategy**: Development-Cache + Production-Snapshots

---

## ğŸ“ Projekt-Struktur

```
Bestands_Forecast/
â”œâ”€â”€ data/                           # ğŸ“Š Finale Datasets (IN GIT!)
â”‚   â”œâ”€â”€ retail_store_inventory.csv      # Rohdaten
â”‚   â”œâ”€â”€ external_features_training.csv  # Feature-Snapshot Training
â”‚   â””â”€â”€ external_features_test.csv      # Feature-Snapshot Test
â”‚
â”œâ”€â”€ cache/                          # ğŸ’¾ TemporÃ¤re API-Caches (NICHT in Git)
â”‚   â”œâ”€â”€ holidays_DE_2024.json
â”‚   â””â”€â”€ bundesbank_rates_*.json
â”‚
â”œâ”€â”€ models/                         # ğŸ¤– Trained Models (optional in Git)
â”‚   â”œâ”€â”€ deepar_final.keras
â”‚   â””â”€â”€ scalers.pkl
â”‚
â”œâ”€â”€ external_features/              # ğŸ”Œ Feature API Package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_client.py                  # Cache, Rate Limiting, Retry
â”‚   â”œâ”€â”€ holiday_client.py               # Feiertags-API
â”‚   â”œâ”€â”€ bundesbank_client.py            # Deutsche Bundesbank API
â”‚   â”œâ”€â”€ orchestrator.py                 # Koordiniert alle APIs
â”‚   â”œâ”€â”€ data_manager.py                 # Hybrid-Strategie Manager
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ Umsatz_Forecast_DeepAR.ipynb    # ğŸ““ Hauptnotebook
â”œâ”€â”€ requirements.txt                 # ğŸ“¦ Dependencies
â”œâ”€â”€ .gitignore                       # ğŸš« Git-AusschlÃ¼sse
â””â”€â”€ README.md                        # ğŸ“– Diese Datei
```

---

## ğŸš€ Quick Start

### 1. Setup

```bash
# Clone Repository
git clone https://github.com/magloving/Bestands_Forecast.git
cd Bestands_Forecast

# Virtual Environment (empfohlen)
python -m venv venv
source venv/bin/activate  # macOS/Linux
# oder: venv\Scripts\activate  # Windows

# Dependencies installieren
pip install -r requirements.txt
```

### 2. Notebook starten

```bash
jupyter notebook Umsatz_Forecast_DeepAR.ipynb
```

### 3. External Features nutzen

```python
from external_features import ExternalFeatureOrchestrator, FeatureDataManager
from datetime import datetime

# Orchestrator initialisieren
orchestrator = ExternalFeatureOrchestrator(country_code="DE")

# Features abrufen (wird automatisch gecacht!)
df_features = orchestrator.get_features_for_range(
    start_date=datetime(2024, 1, 1),
    end_date=datetime(2024, 12, 31)
)

# Finales Training-Dataset exportieren
data_manager = FeatureDataManager()
data_manager.export_training_snapshot(
    features_df=df_features,
    name="training_2024"
)
```

---

## ğŸ’¾ Hybrid Data Strategy

**Best Practice fÃ¼r ML Projects:**

### Development Phase
```python
# âœ… Automatisches Caching (schnell, flexibel)
df = orchestrator.get_features_for_range(...)
# â†’ Speichert in cache/ (24h TTL)
# â†’ Kein CSV nÃ¶tig
# â†’ Perfekt fÃ¼r Experimente
```

### Production Phase
```python
# âœ… Finale CSV-Snapshots (reproduzierbar, versioniert)
data_manager.export_training_snapshot(
    features_df=df,
    name="training_2024"
)
# â†’ Speichert in data/external_features_training_2024.csv
# â†’ UNVERÃ„NDERLICH (nie wieder geÃ¤ndert)
# â†’ Git commit fÃ¼r Reproduzierbarkeit
```

### Vorteile
| Phase | Speicher | Zweck | Git |
|-------|----------|-------|-----|
| Development | `cache/` | Schnelle Iteration | âŒ |
| Training | `data/*.csv` | Reproduzierbare Snapshots | âœ… |
| Production | `cache/` | Live-Predictions | âŒ |

---

## ğŸ”Œ External Features API

### VerfÃ¼gbare Clients

**1. HolidayAPIClient**
- Feiertage fÃ¼r Deutschland
- 3-Layer Fallback (Nager.Date â†’ Calendarific â†’ Local)
- Features: `is_holiday`, `days_to_next_holiday`, `is_holiday_week`

**2. BundesbankAPIClient**
- Deutsche Bundesbank API (keine API Key!)
- EZB Zinsen, Bundesanleihen, Inflation
- Features: `ecb_main_rate`, `german_10y_yield`, `inflation_rate`

**3. ExternalFeatureOrchestrator**
- Koordiniert alle APIs
- Automatisches Caching (24h TTL)
- Batch-Abruf fÃ¼r Datumsbereiche

### Beispiel

```python
orchestrator = ExternalFeatureOrchestrator(country_code="DE")

# Einzelnes Datum
features = orchestrator.get_features_for_date(datetime(2025, 12, 25))

# Datumsbereich (batch)
df_features = orchestrator.get_features_for_range(
    start_date=datetime(2024, 1, 1),
    end_date=datetime(2024, 12, 31)
)

# Feature-Namen
feature_names = orchestrator.get_feature_names()
# â†’ ['is_holiday', 'days_to_next_holiday', 'is_holiday_week',
#    'ezb_hauptrefinanzierung', 'bundesanleihe_10j', ...]
```

---

## ğŸ¤– DeepAR Model

**Probabilistisches Forecasting mit Konfidenzintervallen**

- **Input**: 60-Tage Sequenzen + External Features
- **Output**: Î¼ (Mittelwert) + Ïƒ (Standardabweichung)
- **Loss**: Gaussian Negative Log-Likelihood
- **Architektur**: 2-Layer Bidirectional LSTM (256â†’128 Units)

### Performance
```
MAE:      89.41 Units
Std:      109.77 Units (gut kalibriert!)
Coverage: 86.6% (90% Prediction Intervals)
```

---

## ğŸ“Š Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. DEVELOPMENT                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Nutze cache/ fÃ¼r schnelle Iteration                       â”‚
â”‚ â€¢ Experimentiere mit Features                                â”‚
â”‚ â€¢ Kein Git commit nÃ¶tig                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FINAL TRAINING                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Exportiere CSV-Snapshots (data/)                           â”‚
â”‚ â€¢ Git commit fÃ¼r Reproduzierbarkeit                          â”‚
â”‚ â€¢ Trainiere finales Model                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. PRODUCTION                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Nutze cache/ fÃ¼r neue Predictions                          â”‚
â”‚ â€¢ Live-Daten automatisch gecacht                             â”‚
â”‚ â€¢ Optional: Neue Snapshots fÃ¼r neue ZeitrÃ¤ume                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Dependencies

- **Core**: numpy, pandas, scipy
- **ML**: tensorflow, scikit-learn
- **Viz**: matplotlib, seaborn
- **API**: requests
- **Dev**: jupyter, notebook

Siehe `requirements.txt` fÃ¼r Details.

---

## ğŸ”§ Configuration

### .env (optional)
```bash
# API Keys (nur wenn du NICHT Mock-Daten nutzen willst)
CALENDARIFIC_API_KEY=your_key_here
```

### .gitignore
```gitignore
# TemporÃ¤r (nicht committen)
cache/
*.pkl
models/*.keras

# Daten (committen wenn < 10 MB)
!data/retail_store_inventory.csv
!data/external_features_*.csv
```

---

## ğŸ“ Use Cases

### Studium / Thesis
- âœ… Reproduzierbare Experimente (CSV-Snapshots)
- âœ… Klare Versionierung (Git)
- âœ… Dokumentation (README, Docstrings)

### Production Deployment
- âœ… Live-Predictions (Cache)
- âœ… API-Integration (external_features Package)
- âœ… Monitoring-ready (Logging, Fallbacks)

### Team Collaboration
- âœ… Geteilte Datasets (data/ in Git)
- âœ… Saubere Struktur (modular)
- âœ… Dependencies fixiert (requirements.txt)

---

## ğŸ“š Dokumentation

- **External Features API**: `external_features/README.md`
- **API Setup Guide**: `API_SETUP_GUIDE.md`
- **Notebook**: `Umsatz_Forecast_DeepAR.ipynb` (vollstÃ¤ndig dokumentiert)

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork Repository
2. Create Feature Branch (`git checkout -b feature/amazing-feature`)
3. Commit Changes (`git commit -m 'Add amazing feature'`)
4. Push to Branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

---

## ğŸ“„ License

MIT License - siehe LICENSE Datei

---

## ğŸ‘¤ Author

**Magnus**
- GitHub: [@magloving](https://github.com/magloving)
- Repository: [Bestands_Forecast](https://github.com/magloving/Bestands_Forecast)

---

## ğŸ™ Acknowledgments

- **Deutsche Bundesbank**: Kostenlose Wirtschaftsdaten API
- **Nager.Date**: Kostenlose Feiertags-API
- **TensorFlow/Keras**: Deep Learning Framework
- **DeepAR Paper**: Salinas et al. (2020)

---

**ğŸš€ Happy Forecasting!**
